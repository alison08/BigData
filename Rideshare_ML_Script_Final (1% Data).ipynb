{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, udf, month, year, date_format, datediff, from_unixtime, unix_timestamp\n",
    "from pyspark.sql.functions import date_trunc\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (StructType, StructField, DateType, BooleanType,\n",
    "                               DoubleType, IntegerType, StringType, TimestampType)\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 4 items\n",
      "-rw-r--r--   3 alphan alphan 1824926642 2019-05-25 04:44 /user/alphan/data/chicago_crimes.csv\n",
      "drwxr-xr-x   - alphan alphan          0 2019-06-04 02:09 /user/alphan/data/df.csv\n",
      "drwxr-xr-x   - alphan alphan          0 2019-06-04 02:12 /user/alphan/data/final_project_df.csv\n",
      "-rw-r--r--   3 alphan alphan  208276005 2019-04-30 20:10 /user/alphan/data/food-inspections.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/alphan/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = SparkSession.builder.appName('RideShare2').getOrCreate()\n",
    "conf2 = spark2.sparkContext._conf.setAll([('spark.executor.memory', '15g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','20g')])\n",
    "df = spark2.read.csv(\"/user/alphan/data/final_project_df.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- pickupLat: double (nullable = true)\n",
      " |-- pickupLong: double (nullable = true)\n",
      " |-- dropoffLat: double (nullable = true)\n",
      " |-- dropoffLong: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = SparkSession.builder.appName('RideShare2').getOrCreate()\n",
    "conf = spark2.sparkContext._conf.setAll([('spark.executor.memory', '256g'),\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'),\n",
    "                                        ('spark.executor.cores', '16'),\n",
    "                                        ('spark.cores.max', '16'),\n",
    "                                        ('spark.driver.memory','256g'),\n",
    "                                        ('spark.sql.AutoBroadcastJoinThreshold', -1),\n",
    "                                        ('mapreduce.reduce.memory.mb',-1),\n",
    "                                        ('spark.yarn.executor.memoryOverhead', -1),\n",
    "                                        ('spark.kryoserializer.buffer.max.mb', '5g')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE to HDFS\n",
    "#fulldf = rides.join(spark_weather, rides.startTime == spark_weather.time, how='inner')\n",
    "#res_path = '/user/alphan/data/final_project_df.csv'\n",
    "#df.write.csv(path=res_path, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- pickupLat: double (nullable = true)\n",
      " |-- pickupLong: double (nullable = true)\n",
      " |-- dropoffLat: double (nullable = true)\n",
      " |-- dropoffLong: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[430.0,3.0,0.0,3....|\n",
      "|[368.0,1.9,1.0,44...|\n",
      "|[1142.0,14.7,1.0,...|\n",
      "|[1288.0,3.9,1.0,4...|\n",
      "|[205.0,1.2,0.0,10...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Assemble vectors and Scale:\n",
    "#After iterations examining individual impact, final variable 'columns' below does not contain Longitude & Latitude for easier running\n",
    "\n",
    "columns = ['seconds','miles','shared','communityPickup','communityDropoff','humidity', \n",
    "'apparentTemperature','precipIntensity',\n",
    "'precipProbability', 'temperature', 'Cloudy','Rainy', 'Snowy','month','day', 'hour']\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler,StandardScaler\n",
    "vectorAssembler = VectorAssembler(inputCols = columns, outputCol = 'features')# 'fare', 'addCharge', 'tripTotal'\n",
    "ml_data=vectorAssembler.transform(df)\n",
    "ml_data.select(\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[430.0,3.0,0.0,3....|[0.65134636695970...|\n",
      "|[368.0,1.9,1.0,44...|[0.55743130939807...|\n",
      "|[1142.0,14.7,1.0,...|[1.72985476992555...|\n",
      "|[1288.0,3.9,1.0,4...|[1.95100958289326...|\n",
      "|[205.0,1.2,0.0,10...|[0.31052559355055...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standardscaler=StandardScaler().setInputCol('features').setOutputCol('scaled_features')\n",
    "scaled_data=standardscaler.fit(ml_data).transform(ml_data)\n",
    "scaled_data.select('features','scaled_features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|     scaled_features|fare|\n",
      "+--------------------+----+\n",
      "|[0.65134636695970...| 7.5|\n",
      "|[0.55743130939807...| 5.0|\n",
      "|[1.72985476992555...|17.5|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vfull_df = scaled_data.select(['scaled_features', 'fare'])\n",
    "vfull_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of some of the models below changed noticeably for the better after setting the seed, and thus may differ slightly from the results from the presentation slide. The previous script did not have a seed setting. The rest of the script remains as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "splits = scaled_data.randomSplit([0.99, 0.01], seed=SEED)\n",
    "small_df = splits[1]\n",
    "small_split = small_df.randomSplit([0.7, 0.3],seed=SEED)\n",
    "train_df = small_split[0]\n",
    "test_df = small_split[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'fare')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "dt_rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "dt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "dt_r2 = dt_evaluator2.evaluate(dt_predictions)\n",
    "dt_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "dt_mae= dt_evaluator3.evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.08866\n",
      "R-Squared (R2) on test data = 0.792706\n",
      "Mean Absolute Error (MAE) on test data = 1.64751\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % dt_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % dt_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % dt_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from FeatureImportanceSelector import ExtractFeatureImp, FeatureImpSelector\n",
    "ExtractFeatureImp(mod.stages[-1].featureImportances, dt_predictions, \"features_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.792715</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106965</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097684</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001030</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values             features\n",
       "1   0.792715                miles\n",
       "2   0.106965               shared\n",
       "0   0.097684              seconds\n",
       "4   0.001424     communityDropoff\n",
       "3   0.001030      communityPickup\n",
       "9   0.000182          temperature\n",
       "5   0.000000             humidity\n",
       "6   0.000000  apparentTemperature\n",
       "7   0.000000      precipIntensity\n",
       "8   0.000000    precipProbability\n",
       "10  0.000000               Cloudy\n",
       "11  0.000000                Rainy\n",
       "12  0.000000                Snowy\n",
       "13  0.000000                month\n",
       "14  0.000000                  day\n",
       "15  0.000000                 hour"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(dt_model.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|fare|            features|\n",
      "+------------------+----+--------------------+\n",
      "| 3.117913782281579| 2.5|[51.0,0.1,0.0,8.0...|\n",
      "|3.0618915535250624| 2.5|[57.0,0.2,1.0,23....|\n",
      "|3.0246523233774725| 2.5|[58.0,0.2,0.0,32....|\n",
      "| 3.036138878680659| 2.5|[61.0,0.2,0.0,8.0...|\n",
      "| 3.036138878680659| 2.5|[73.0,0.2,0.0,26....|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'fare', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'fare', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "gbt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "gbt_r2 = gbt_evaluator2.evaluate(gbt_predictions)\n",
    "gbt_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "gbt_mae = gbt_evaluator3.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.94064\n",
      "R-Squared (R2) on test data = 0.810466\n",
      "Mean Absolute Error (MAE) on test data = 1.56672\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % gbt_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % gbt_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % gbt_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393758</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321471</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103609</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046849</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.034539</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027559</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021082</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014972</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010923</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008051</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005578</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004063</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003024</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001789</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001740</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000993</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values             features\n",
       "1   0.393758                miles\n",
       "0   0.321471              seconds\n",
       "2   0.103609               shared\n",
       "3   0.046849      communityPickup\n",
       "15  0.034539                 hour\n",
       "4   0.027559     communityDropoff\n",
       "14  0.021082                  day\n",
       "9   0.014972          temperature\n",
       "6   0.010923  apparentTemperature\n",
       "5   0.008051             humidity\n",
       "8   0.005578    precipProbability\n",
       "13  0.004063                month\n",
       "12  0.003024                Snowy\n",
       "10  0.001789               Cloudy\n",
       "11  0.001740                Rainy\n",
       "7   0.000993      precipIntensity"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(gbt_model.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+--------------------+\n",
      "|       prediction|fare|            features|\n",
      "+-----------------+----+--------------------+\n",
      "|4.890041596394282| 2.5|[51.0,0.1,0.0,8.0...|\n",
      "| 4.72350579959502| 2.5|[57.0,0.2,1.0,23....|\n",
      "|4.823513771121112| 2.5|[58.0,0.2,0.0,32....|\n",
      "|4.741040431993048| 2.5|[61.0,0.2,0.0,8.0...|\n",
      "|4.714938375021649| 2.5|[73.0,0.2,0.0,26....|\n",
      "+-----------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'fare')\n",
    "rfModel = rf.fit(train_df)\n",
    "rf_predictions = rfModel.transform(test_df)\n",
    "rf_predictions.select('prediction', 'fare', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rf_rmse = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "rf_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rf_r2 = rf_evaluator2.evaluate(rf_predictions)\n",
    "rf_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "rf_mae = rf_evaluator3.evaluate(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.07921\n",
      "R-Squared (R2) on test data = 0.791748\n",
      "Mean Absolute Error (MAE) on test data = 1.66351\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rf_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % rf_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % rf_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.176079e-01</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.293197e-01</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.009469e-02</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.391204e-02</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.745107e-02</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.164290e-03</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.772842e-04</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.638586e-05</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.275432e-05</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.183826e-05</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.139675e-05</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.005391e-05</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.504703e-07</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          values             features\n",
       "1   6.176079e-01                miles\n",
       "0   2.293197e-01              seconds\n",
       "4   7.009469e-02     communityDropoff\n",
       "2   6.391204e-02               shared\n",
       "3   1.745107e-02      communityPickup\n",
       "15  1.164290e-03                 hour\n",
       "14  2.772842e-04                  day\n",
       "9   5.638586e-05          temperature\n",
       "13  4.275432e-05                month\n",
       "8   3.183826e-05    precipProbability\n",
       "5   2.139675e-05             humidity\n",
       "6   2.005391e-05  apparentTemperature\n",
       "7   5.504703e-07      precipIntensity\n",
       "10  0.000000e+00               Cloudy\n",
       "11  0.000000e+00                Rainy\n",
       "12  0.000000e+00                Snowy"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(rfModel.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0020188080253334038,0.9925907827753835,-3.3895853600260293,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Intercept: 3.722830854394592\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='fare', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.361395\n",
      "r2: 0.761311\n",
      "MAE: 1.877613\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n",
    "print(\"MAE: %f\" % trainingSummary.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_data = test_df.select(col(\"fare\").alias(\"label\"), *columns)  \n",
    "lr_data.printSchema()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "rfr = RandomForestRegressor(labelCol=\"label\", featuresCol=\"scaled_features\")\n",
    "stages = [vectorAssembler, standardscaler, rfr]\n",
    "pipe = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorParam = ParamGridBuilder() \\\n",
    ".addGrid(rfr.maxDepth, [4, 6,8]) \\\n",
    ".addGrid(rfr.maxBins, [5, 10, 15]) \\\n",
    ".addGrid(rfr.impurity, [\"variance\"]) \\\n",
    ".build()\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipe,\n",
    "                         estimatorParamMaps=estimatorParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "cvmodel = crossval.fit(lr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=RegressionEvaluator()\n",
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\")\n",
    "eval_r2 = RegressionEvaluator(metricName=\"r2\")\n",
    "eval_mae = RegressionEvaluator(metricName=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8894086933239036\n",
      "0.8166299271058671\n",
      "1.534910661838085\n"
     ]
    }
   ],
   "source": [
    "#Not sure it matters what data we use here\n",
    "print(eval_rmse.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_r2.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_mae.evaluate(cvmodel.transform(lr_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(labelCol=\"label\", featuresCol=\"scaled_features\")\n",
    "stages = [vectorAssembler, standardscaler, gbt]\n",
    "pipe = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorParam = ParamGridBuilder() \\\n",
    ".addGrid(rfr.maxDepth, [4, 6,8]) \\\n",
    ".addGrid(rfr.maxBins, [5, 10, 15]) \\\n",
    ".addGrid(rfr.impurity, [\"variance\"]) \\\n",
    ".build()\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipe,\n",
    "                         estimatorParamMaps=estimatorParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "cvmodel = crossval.fit(lr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=RegressionEvaluator()\n",
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\")\n",
    "eval_r2 = RegressionEvaluator(metricName=\"r2\")\n",
    "eval_mae = RegressionEvaluator(metricName=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.804763596021153\n",
      "0.8272161959633803\n",
      "1.5185055819271953\n"
     ]
    }
   ],
   "source": [
    "print(eval_rmse.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_r2.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_mae.evaluate(cvmodel.transform(lr_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
