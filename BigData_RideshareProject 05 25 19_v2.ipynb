{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIDESHARE PRICE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RIDESHARE DATA ON RCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 11 items\n",
      "-rw-r--r--   3 mechols mechols        1708 2019-05-17 14:10 /user/mechols/data/chicago_community_names.csv\n",
      "-rw-r--r--   3 mechols mechols  1804333782 2019-05-16 21:03 /user/mechols/data/chicago_crimes.csv\n",
      "-rw-r--r--   3 mechols mechols       83421 2019-05-24 20:20 /user/mechols/data/december_weather.csv\n",
      "-rw-r--r--   3 mechols mechols       75982 2019-05-24 20:20 /user/mechols/data/february_weather.csv\n",
      "-rw-r--r--   3 mechols mechols   208276005 2019-04-30 20:04 /user/mechols/data/food-inspections.csv\n",
      "-rw-r--r--   3 mechols mechols       85301 2019-05-24 20:20 /user/mechols/data/january_weather.csv\n",
      "-rw-r--r--   3 mechols mechols       82985 2019-05-24 20:20 /user/mechols/data/march_weather.csv\n",
      "-rw-r--r--   3 mechols mechols       72336 2019-05-24 22:45 /user/mechols/data/march_weatherUpdated.csv\n",
      "-rw-r--r--   3 mechols mechols       83817 2019-05-24 20:20 /user/mechols/data/november_weather.csv\n",
      "-rw-r--r--   3 mechols mechols 11980344386 2019-05-21 14:25 /user/mechols/data/rows.csv\n",
      "drwxr-xr-x   - mechols mechols           0 2019-05-25 11:15 /user/mechols/data/weather_data\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/mechols/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('RideShare').getOrCreate()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '15g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','20g')])\n",
    "df = spark.read.csv(\"/user/mechols/data/rows.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data consists of +45m rows and 21 columns. \n",
    "* % of non-null = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: string (nullable = true)\n",
      " |-- Trip End Timestamp: string (nullable = true)\n",
      " |-- Trip Seconds: integer (nullable = true)\n",
      " |-- Trip Miles: double (nullable = true)\n",
      " |-- Pickup Census Tract: long (nullable = true)\n",
      " |-- Dropoff Census Tract: long (nullable = true)\n",
      " |-- Pickup Community Area: integer (nullable = true)\n",
      " |-- Dropoff Community Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: integer (nullable = true)\n",
      " |-- Additional Charges: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- Shared Trip Authorized: boolean (nullable = true)\n",
      " |-- Trips Pooled: integer (nullable = true)\n",
      " |-- Pickup Centroid Latitude: double (nullable = true)\n",
      " |-- Pickup Centroid Longitude: double (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip ID</th>\n",
       "      <td>45338599</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0000000fb973b32717a335d3b7dd66deca2c5624</td>\n",
       "      <td>fffffff98e06990a5a5de341681890b9d433dfe2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <td>45338599</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>01/01/2019 01:00:00 AM</td>\n",
       "      <td>12/31/2018 12:45:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip End Timestamp</th>\n",
       "      <td>45338599</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>01/01/2019 01:00:00 AM</td>\n",
       "      <td>12/31/2018 12:45:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Seconds</th>\n",
       "      <td>45335173</td>\n",
       "      <td>1055.0425702798134</td>\n",
       "      <td>756.1997634637894</td>\n",
       "      <td>0</td>\n",
       "      <td>85080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Miles</th>\n",
       "      <td>45338595</td>\n",
       "      <td>5.871021585472638</td>\n",
       "      <td>6.5615330186674035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Census Tract</th>\n",
       "      <td>32772415</td>\n",
       "      <td>1.7031364181660095E10</td>\n",
       "      <td>333041.5090314861</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>17031980100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Census Tract</th>\n",
       "      <td>32598614</td>\n",
       "      <td>1.7031374560267588E10</td>\n",
       "      <td>337803.256079789</td>\n",
       "      <td>17031010100</td>\n",
       "      <td>17031980100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <td>42687384</td>\n",
       "      <td>25.322439833745726</td>\n",
       "      <td>20.154856059115907</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <td>42369138</td>\n",
       "      <td>25.902587775092332</td>\n",
       "      <td>20.513990604732157</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>45338474</td>\n",
       "      <td>10.808503501904365</td>\n",
       "      <td>9.219717584772912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tip</th>\n",
       "      <td>45338582</td>\n",
       "      <td>0.5260001073699218</td>\n",
       "      <td>1.5583778202512757</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Additional Charges</th>\n",
       "      <td>45338478</td>\n",
       "      <td>2.800768962683609</td>\n",
       "      <td>1.8654995657933675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Total</th>\n",
       "      <td>45338474</td>\n",
       "      <td>14.135272461843789</td>\n",
       "      <td>10.872138810415198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1402.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trips Pooled</th>\n",
       "      <td>45338599</td>\n",
       "      <td>1.332464507780666</td>\n",
       "      <td>0.8112686222488744</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <td>42716681</td>\n",
       "      <td>41.892402323074876</td>\n",
       "      <td>0.06130789585239493</td>\n",
       "      <td>41.6502216756</td>\n",
       "      <td>42.0212235931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <td>42716681</td>\n",
       "      <td>-87.66579038461725</td>\n",
       "      <td>0.05982124181543208</td>\n",
       "      <td>-87.913624596</td>\n",
       "      <td>-87.529950466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Location</th>\n",
       "      <td>42716681</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-87.529950466 41.6954498278)</td>\n",
       "      <td>POINT (-87.913624596 41.9802643146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <td>42397962</td>\n",
       "      <td>41.89304940209333</td>\n",
       "      <td>0.06139117275357228</td>\n",
       "      <td>41.6502216756</td>\n",
       "      <td>42.0212235931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <td>42397962</td>\n",
       "      <td>-87.66754188665794</td>\n",
       "      <td>0.06339619996512846</td>\n",
       "      <td>-87.913624596</td>\n",
       "      <td>-87.529950466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Location</th>\n",
       "      <td>42397962</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-87.529950466 41.6954498278)</td>\n",
       "      <td>POINT (-87.913624596 41.9802643146)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                      1  \\\n",
       "summary                        count                   mean   \n",
       "Trip ID                     45338599               Infinity   \n",
       "Trip Start Timestamp        45338599                   None   \n",
       "Trip End Timestamp          45338599                   None   \n",
       "Trip Seconds                45335173     1055.0425702798134   \n",
       "Trip Miles                  45338595      5.871021585472638   \n",
       "Pickup Census Tract         32772415  1.7031364181660095E10   \n",
       "Dropoff Census Tract        32598614  1.7031374560267588E10   \n",
       "Pickup Community Area       42687384     25.322439833745726   \n",
       "Dropoff Community Area      42369138     25.902587775092332   \n",
       "Fare                        45338474     10.808503501904365   \n",
       "Tip                         45338582     0.5260001073699218   \n",
       "Additional Charges          45338478      2.800768962683609   \n",
       "Trip Total                  45338474     14.135272461843789   \n",
       "Trips Pooled                45338599      1.332464507780666   \n",
       "Pickup Centroid Latitude    42716681     41.892402323074876   \n",
       "Pickup Centroid Longitude   42716681     -87.66579038461725   \n",
       "Pickup Centroid Location    42716681                   None   \n",
       "Dropoff Centroid Latitude   42397962      41.89304940209333   \n",
       "Dropoff Centroid Longitude  42397962     -87.66754188665794   \n",
       "Dropoff Centroid Location   42397962                   None   \n",
       "\n",
       "                                              2  \\\n",
       "summary                                  stddev   \n",
       "Trip ID                                     NaN   \n",
       "Trip Start Timestamp                       None   \n",
       "Trip End Timestamp                         None   \n",
       "Trip Seconds                  756.1997634637894   \n",
       "Trip Miles                   6.5615330186674035   \n",
       "Pickup Census Tract           333041.5090314861   \n",
       "Dropoff Census Tract           337803.256079789   \n",
       "Pickup Community Area        20.154856059115907   \n",
       "Dropoff Community Area       20.513990604732157   \n",
       "Fare                          9.219717584772912   \n",
       "Tip                          1.5583778202512757   \n",
       "Additional Charges           1.8654995657933675   \n",
       "Trip Total                   10.872138810415198   \n",
       "Trips Pooled                 0.8112686222488744   \n",
       "Pickup Centroid Latitude    0.06130789585239493   \n",
       "Pickup Centroid Longitude   0.05982124181543208   \n",
       "Pickup Centroid Location                   None   \n",
       "Dropoff Centroid Latitude   0.06139117275357228   \n",
       "Dropoff Centroid Longitude  0.06339619996512846   \n",
       "Dropoff Centroid Location                  None   \n",
       "\n",
       "                                                                   3  \\\n",
       "summary                                                          min   \n",
       "Trip ID                     0000000fb973b32717a335d3b7dd66deca2c5624   \n",
       "Trip Start Timestamp                          01/01/2019 01:00:00 AM   \n",
       "Trip End Timestamp                            01/01/2019 01:00:00 AM   \n",
       "Trip Seconds                                                       0   \n",
       "Trip Miles                                                       0.0   \n",
       "Pickup Census Tract                                      17031010100   \n",
       "Dropoff Census Tract                                     17031010100   \n",
       "Pickup Community Area                                              1   \n",
       "Dropoff Community Area                                             1   \n",
       "Fare                                                             0.0   \n",
       "Tip                                                                0   \n",
       "Additional Charges                                               0.0   \n",
       "Trip Total                                                       0.0   \n",
       "Trips Pooled                                                       1   \n",
       "Pickup Centroid Latitude                               41.6502216756   \n",
       "Pickup Centroid Longitude                              -87.913624596   \n",
       "Pickup Centroid Location         POINT (-87.529950466 41.6954498278)   \n",
       "Dropoff Centroid Latitude                              41.6502216756   \n",
       "Dropoff Centroid Longitude                             -87.913624596   \n",
       "Dropoff Centroid Location        POINT (-87.529950466 41.6954498278)   \n",
       "\n",
       "                                                                   4  \n",
       "summary                                                          max  \n",
       "Trip ID                     fffffff98e06990a5a5de341681890b9d433dfe2  \n",
       "Trip Start Timestamp                          12/31/2018 12:45:00 PM  \n",
       "Trip End Timestamp                            12/31/2018 12:45:00 PM  \n",
       "Trip Seconds                                                   85080  \n",
       "Trip Miles                                                     389.9  \n",
       "Pickup Census Tract                                      17031980100  \n",
       "Dropoff Census Tract                                     17031980100  \n",
       "Pickup Community Area                                             77  \n",
       "Dropoff Community Area                                            77  \n",
       "Fare                                                          1400.0  \n",
       "Tip                                                              200  \n",
       "Additional Charges                                             79.71  \n",
       "Trip Total                                                   1402.05  \n",
       "Trips Pooled                                                      17  \n",
       "Pickup Centroid Latitude                               42.0212235931  \n",
       "Pickup Centroid Longitude                              -87.529950466  \n",
       "Pickup Centroid Location         POINT (-87.913624596 41.9802643146)  \n",
       "Dropoff Centroid Latitude                              42.0212235931  \n",
       "Dropoff Centroid Longitude                             -87.529950466  \n",
       "Dropoff Centroid Location        POINT (-87.913624596 41.9802643146)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45338599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "sampled_data = df.select(numeric_features).sample(False, 0.8).toPandas()\n",
    "axs = pd.scatter_matrix(sampled_data, figsize=(10, 10))\n",
    "n = len(sampled_data.columns)\n",
    "for i in range(n):\n",
    "    v = axs[i, 0]\n",
    "    v.yaxis.label.set_rotation(0)\n",
    "    v.yaxis.label.set_ha('right')\n",
    "    v.set_yticks(())\n",
    "    h = axs[n-1, i]\n",
    "    h.xaxis.label.set_rotation(90)\n",
    "    h.set_xticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Correlation to Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(*(col(c).cast(\"int\").alias(c) for c in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to Fare for  Trip ID nan\n",
      "Correlation to Fare for  Trip Start Timestamp nan\n",
      "Correlation to Fare for  Trip End Timestamp nan\n",
      "Correlation to Fare for  Trip Seconds 0.7610519330527545\n",
      "Correlation to Fare for  Trip Miles 0.8800238813912881\n",
      "Correlation to Fare for  Pickup Census Tract 0.12351125331263813\n",
      "Correlation to Fare for  Dropoff Census Tract 0.14385608650069356\n",
      "Correlation to Fare for  Pickup Community Area 0.1073022936904991\n",
      "Correlation to Fare for  Dropoff Community Area 0.12435471526430804\n",
      "Correlation to Fare for  Fare 1.0\n",
      "Correlation to Fare for  Tip 0.30951016812970517\n",
      "Correlation to Fare for  Additional Charges 0.5023987537532858\n",
      "Correlation to Fare for  Trip Total 0.9755596285884255\n",
      "Correlation to Fare for  Shared Trip Authorized -0.18985457788489718\n",
      "Correlation to Fare for  Trips Pooled -0.16748416019728882\n",
      "Correlation to Fare for  Pickup Centroid Latitude -0.2767500613646875\n",
      "Correlation to Fare for  Pickup Centroid Longitude 0.27677545398817\n",
      "Correlation to Fare for  Pickup Centroid Location nan\n",
      "Correlation to Fare for  Dropoff Centroid Latitude -0.3164184256541948\n",
      "Correlation to Fare for  Dropoff Centroid Longitude 0.31645470057748903\n",
      "Correlation to Fare for  Dropoff Centroid Location nan\n",
      "Correlation to Fare for  dt_truncated nan\n",
      "Correlation to Fare for  date_hour nan\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "for i in df.columns:\n",
    "    if not( isinstance(df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to Fare for \", i, df.stat.corr('Fare',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NULL VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Majority of data filled in. Census Tract at ~70% , field should be dropped\n",
    "* Do we think we will use lat / long data or mostly community area? If just community, we should drop all the lat, long data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip ID: bigint, Trip Start Timestamp: bigint, Trip End Timestamp: bigint, Trip Seconds: bigint, Trip Miles: bigint, Pickup Community Area: bigint, Dropoff Community Area: bigint, Fare: bigint, Tip: bigint, Additional Charges: bigint, Trip Total: bigint, Shared Trip Authorized: bigint, Trips Pooled: bigint, Pickup Centroid Latitude: bigint, Pickup Centroid Longitude: bigint, Pickup Centroid Location: bigint, Dropoff Centroid Latitude: bigint, Dropoff Centroid Longitude: bigint, Dropoff Centroid Location: bigint, Pickup Community Area Filled: bigint]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, lit, sum\n",
    "\n",
    "def count_not_null(c, nan_as_null=False):\n",
    "    \"\"\"Use conversion between boolean and integer\n",
    "    - False -> 0\n",
    "    - True ->  1\n",
    "    \"\"\"\n",
    "    pred = col(c).isNotNull() & (~isnan(c) if nan_as_null else lit(True))\n",
    "    return sum(pred.cast(\"integer\")).alias(c)\n",
    "\n",
    "df.agg(*[count_not_null(c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exprs = [(count_not_null(c) / count(\"*\")).alias(c) for c in df.columns]\n",
    "NonNullData = df.agg(*exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trip ID</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Start Timestamp</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip End Timestamp</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Seconds</th>\n",
       "      <td>0.999924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Miles</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Community Area</th>\n",
       "      <td>0.941524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Community Area</th>\n",
       "      <td>0.934505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tip</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Additional Charges</th>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip Total</th>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared Trip Authorized</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trips Pooled</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Latitude</th>\n",
       "      <td>0.942170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Longitude</th>\n",
       "      <td>0.942170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Centroid Location</th>\n",
       "      <td>0.942170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Latitude</th>\n",
       "      <td>0.935141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Longitude</th>\n",
       "      <td>0.935141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dropoff Centroid Location</th>\n",
       "      <td>0.935141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup Community Area Filled</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "Trip ID                       1.000000\n",
       "Trip Start Timestamp          1.000000\n",
       "Trip End Timestamp            1.000000\n",
       "Trip Seconds                  0.999924\n",
       "Trip Miles                    1.000000\n",
       "Pickup Community Area         0.941524\n",
       "Dropoff Community Area        0.934505\n",
       "Fare                          0.999997\n",
       "Tip                           1.000000\n",
       "Additional Charges            0.999997\n",
       "Trip Total                    0.999997\n",
       "Shared Trip Authorized        1.000000\n",
       "Trips Pooled                  1.000000\n",
       "Pickup Centroid Latitude      0.942170\n",
       "Pickup Centroid Longitude     0.942170\n",
       "Pickup Centroid Location      0.942170\n",
       "Dropoff Centroid Latitude     0.935141\n",
       "Dropoff Centroid Longitude    0.935141\n",
       "Dropoff Centroid Location     0.935141\n",
       "Pickup Community Area Filled  1.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NonNull = NonNullData.toPandas()\n",
    "PercentFilled = NonNull.T\n",
    "PercentFilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Pickup Census Tract\", \"Dropoff Census Tract\")\n",
    "\n",
    "#if we decide not to use lat / long data\n",
    "\n",
    "#df = df.drop(\"Pickup Census Tract\", \"Dropoff Census Tract\",\"Pickup Centroid Latitude\",\n",
    "#             \"Pickup Centroid Longitude\",\"Dropoff Centroid Latitude\",\"Dropoff Centroid Longitude\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPUTATION  - Forward Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not sure what makes the most sense -- should we just drop fields with blank pickup community areas? Not sure how we would fill in a way that is accurate? \n",
    "* Was thinking 'Forward Fill' code listed below but sorting by time doesn't give us any insight to where they were picked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import last\n",
    "import sys\n",
    "\n",
    "# define the window\n",
    "window = Window.orderBy('Trip Start Timestamp')\\\n",
    "               .rowsBetween(-sys.maxsize, 0)\n",
    "\n",
    "# define the forward-filled column\n",
    "filled_column_temperature = last(df['Pickup Community Area'], ignorenulls=True).over(window)\n",
    "\n",
    "# do the fill \n",
    "df = df.withColumn('Pickup Community Area Filled',  filled_column_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding a new column 'dt_truncated' - Date rounded to closest hour -- to match to weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, unix_timestamp, round\n",
    "\n",
    "date_hour = ((round(unix_timestamp(col(\"Trip Start Timestamp\")) / 12) * 12)\n",
    "    .cast(\"timestamp\"))\n",
    "\n",
    "df = df.withColumn(\"date_hour\", date_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD IMPUTATION ATTEMPS (IGNORE) - Getting errors due to data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "toImpute = df.select(\"Pickup Community Area\",\"Dropoff Community Area\",\"Fare\",\n",
    "                           \"Additional Charges\",\"Trip Total\")\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=df.columns, \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in toImpute.columns]\n",
    ")\n",
    "imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(inputCols=[\"Pickup Community Area\",\"Dropoff Community Area\",\"Fare\",\n",
    "                           \"Additional Charges\",\"Trip Total\"],\n",
    "                outputCols=[\"Pickup Community Area\",\"Dropoff Community Area\",\"Fare\",\n",
    "                           \"Additional Charges\",\"Trip Total\"])\n",
    "model=imputer.fit(df)\n",
    "df=model.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`features`' given input columns: [Fare, Dropoff Centroid Location, Dropoff Centroid Longitude, Shared Trip Authorized, Trip End Timestamp, Trips Pooled, Trip Total, Pickup Census Tract, Trip Start Timestamp, Dropoff Community Area, Trip ID, Dropoff Centroid Latitude, date_hour, Pickup Centroid Location, Trip Seconds, Pickup Centroid Latitude, Pickup Centroid Longitude, Pickup Community Area, Additional Charges, dt_truncated, Dropoff Census Tract, Tip, Trip Miles];;\\n'Project ['features, Fare#2156]\\n+- Project [cast(Trip ID#10 as int) AS Trip ID#2147, cast(Trip Start Timestamp#11 as int) AS Trip Start Timestamp#2148, cast(Trip End Timestamp#12 as int) AS Trip End Timestamp#2149, cast(Trip Seconds#13 as int) AS Trip Seconds#2150, cast(Trip Miles#14 as int) AS Trip Miles#2151, cast(Pickup Census Tract#15L as int) AS Pickup Census Tract#2152, cast(Dropoff Census Tract#16L as int) AS Dropoff Census Tract#2153, cast(Pickup Community Area#17 as int) AS Pickup Community Area#2154, cast(Dropoff Community Area#18 as int) AS Dropoff Community Area#2155, cast(Fare#19 as int) AS Fare#2156, cast(Tip#20 as int) AS Tip#2157, cast(Additional Charges#21 as int) AS Additional Charges#2158, cast(Trip Total#22 as int) AS Trip Total#2159, cast(Shared Trip Authorized#23 as int) AS Shared Trip Authorized#2160, cast(Trips Pooled#24 as int) AS Trips Pooled#2161, cast(Pickup Centroid Latitude#25 as int) AS Pickup Centroid Latitude#2162, cast(Pickup Centroid Longitude#26 as int) AS Pickup Centroid Longitude#2163, cast(Pickup Centroid Location#27 as int) AS Pickup Centroid Location#2164, cast(Dropoff Centroid Latitude#28 as int) AS Dropoff Centroid Latitude#2165, cast(Dropoff Centroid Longitude#29 as int) AS Dropoff Centroid Longitude#2166, cast(Dropoff Centroid Location#30 as int) AS Dropoff Centroid Location#2167, cast(dt_truncated#1330 as int) AS dt_truncated#2168, cast(date_hour#1397 as int) AS date_hour#2169]\\n   +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, dt_truncated#1330, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS date_hour#1397]\\n      +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1330]\\n         +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1263]\\n            +- Relation[Trip ID#10,Trip Start Timestamp#11,Trip End Timestamp#12,Trip Seconds#13,Trip Miles#14,Pickup Census Tract#15L,Dropoff Census Tract#16L,Pickup Community Area#17,Dropoff Community Area#18,Fare#19,Tip#20,Additional Charges#21,Trip Total#22,Shared Trip Authorized#23,Trips Pooled#24,Pickup Centroid Latitude#25,Pickup Centroid Longitude#26,Pickup Centroid Location#27,Dropoff Centroid Latitude#28,Dropoff Centroid Longitude#29,Dropoff Centroid Location#30] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o891.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`features`' given input columns: [Fare, Dropoff Centroid Location, Dropoff Centroid Longitude, Shared Trip Authorized, Trip End Timestamp, Trips Pooled, Trip Total, Pickup Census Tract, Trip Start Timestamp, Dropoff Community Area, Trip ID, Dropoff Centroid Latitude, date_hour, Pickup Centroid Location, Trip Seconds, Pickup Centroid Latitude, Pickup Centroid Longitude, Pickup Community Area, Additional Charges, dt_truncated, Dropoff Census Tract, Tip, Trip Miles];;\n'Project ['features, Fare#2156]\n+- Project [cast(Trip ID#10 as int) AS Trip ID#2147, cast(Trip Start Timestamp#11 as int) AS Trip Start Timestamp#2148, cast(Trip End Timestamp#12 as int) AS Trip End Timestamp#2149, cast(Trip Seconds#13 as int) AS Trip Seconds#2150, cast(Trip Miles#14 as int) AS Trip Miles#2151, cast(Pickup Census Tract#15L as int) AS Pickup Census Tract#2152, cast(Dropoff Census Tract#16L as int) AS Dropoff Census Tract#2153, cast(Pickup Community Area#17 as int) AS Pickup Community Area#2154, cast(Dropoff Community Area#18 as int) AS Dropoff Community Area#2155, cast(Fare#19 as int) AS Fare#2156, cast(Tip#20 as int) AS Tip#2157, cast(Additional Charges#21 as int) AS Additional Charges#2158, cast(Trip Total#22 as int) AS Trip Total#2159, cast(Shared Trip Authorized#23 as int) AS Shared Trip Authorized#2160, cast(Trips Pooled#24 as int) AS Trips Pooled#2161, cast(Pickup Centroid Latitude#25 as int) AS Pickup Centroid Latitude#2162, cast(Pickup Centroid Longitude#26 as int) AS Pickup Centroid Longitude#2163, cast(Pickup Centroid Location#27 as int) AS Pickup Centroid Location#2164, cast(Dropoff Centroid Latitude#28 as int) AS Dropoff Centroid Latitude#2165, cast(Dropoff Centroid Longitude#29 as int) AS Dropoff Centroid Longitude#2166, cast(Dropoff Centroid Location#30 as int) AS Dropoff Centroid Location#2167, cast(dt_truncated#1330 as int) AS dt_truncated#2168, cast(date_hour#1397 as int) AS date_hour#2169]\n   +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, dt_truncated#1330, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS date_hour#1397]\n      +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1330]\n         +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1263]\n            +- Relation[Trip ID#10,Trip Start Timestamp#11,Trip End Timestamp#12,Trip Seconds#13,Trip Miles#14,Pickup Census Tract#15L,Dropoff Census Tract#16L,Pickup Community Area#17,Dropoff Community Area#18,Fare#19,Tip#20,Additional Charges#21,Trip Total#22,Shared Trip Authorized#23,Trips Pooled#24,Pickup Centroid Latitude#25,Pickup Centroid Longitude#26,Pickup Centroid Location#27,Dropoff Centroid Latitude#28,Dropoff Centroid Longitude#29,Dropoff Centroid Location#30] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3406)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1334)\n\tat sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f52d0957e7e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 ], outputCol = 'features')\n\u001b[1;32m      6\u001b[0m \u001b[0mv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorAssembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \"\"\"\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`features`' given input columns: [Fare, Dropoff Centroid Location, Dropoff Centroid Longitude, Shared Trip Authorized, Trip End Timestamp, Trips Pooled, Trip Total, Pickup Census Tract, Trip Start Timestamp, Dropoff Community Area, Trip ID, Dropoff Centroid Latitude, date_hour, Pickup Centroid Location, Trip Seconds, Pickup Centroid Latitude, Pickup Centroid Longitude, Pickup Community Area, Additional Charges, dt_truncated, Dropoff Census Tract, Tip, Trip Miles];;\\n'Project ['features, Fare#2156]\\n+- Project [cast(Trip ID#10 as int) AS Trip ID#2147, cast(Trip Start Timestamp#11 as int) AS Trip Start Timestamp#2148, cast(Trip End Timestamp#12 as int) AS Trip End Timestamp#2149, cast(Trip Seconds#13 as int) AS Trip Seconds#2150, cast(Trip Miles#14 as int) AS Trip Miles#2151, cast(Pickup Census Tract#15L as int) AS Pickup Census Tract#2152, cast(Dropoff Census Tract#16L as int) AS Dropoff Census Tract#2153, cast(Pickup Community Area#17 as int) AS Pickup Community Area#2154, cast(Dropoff Community Area#18 as int) AS Dropoff Community Area#2155, cast(Fare#19 as int) AS Fare#2156, cast(Tip#20 as int) AS Tip#2157, cast(Additional Charges#21 as int) AS Additional Charges#2158, cast(Trip Total#22 as int) AS Trip Total#2159, cast(Shared Trip Authorized#23 as int) AS Shared Trip Authorized#2160, cast(Trips Pooled#24 as int) AS Trips Pooled#2161, cast(Pickup Centroid Latitude#25 as int) AS Pickup Centroid Latitude#2162, cast(Pickup Centroid Longitude#26 as int) AS Pickup Centroid Longitude#2163, cast(Pickup Centroid Location#27 as int) AS Pickup Centroid Location#2164, cast(Dropoff Centroid Latitude#28 as int) AS Dropoff Centroid Latitude#2165, cast(Dropoff Centroid Longitude#29 as int) AS Dropoff Centroid Longitude#2166, cast(Dropoff Centroid Location#30 as int) AS Dropoff Centroid Location#2167, cast(dt_truncated#1330 as int) AS dt_truncated#2168, cast(date_hour#1397 as int) AS date_hour#2169]\\n   +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, dt_truncated#1330, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS date_hour#1397]\\n      +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1330]\\n         +- Project [Trip ID#10, Trip Start Timestamp#11, Trip End Timestamp#12, Trip Seconds#13, Trip Miles#14, Pickup Census Tract#15L, Dropoff Census Tract#16L, Pickup Community Area#17, Dropoff Community Area#18, Fare#19, Tip#20, Additional Charges#21, Trip Total#22, Shared Trip Authorized#23, Trips Pooled#24, Pickup Centroid Latitude#25, Pickup Centroid Longitude#26, Pickup Centroid Location#27, Dropoff Centroid Latitude#28, Dropoff Centroid Longitude#29, Dropoff Centroid Location#30, cast((round((cast(unix_timestamp(Trip Start Timestamp#11, yyyy-MM-dd HH:mm:ss, Some(America/Chicago)) as double) / cast(12 as double)), 0) * cast(12 as double)) as timestamp) AS dt_truncated#1263]\\n            +- Relation[Trip ID#10,Trip Start Timestamp#11,Trip End Timestamp#12,Trip Seconds#13,Trip Miles#14,Pickup Census Tract#15L,Dropoff Census Tract#16L,Pickup Community Area#17,Dropoff Community Area#18,Fare#19,Tip#20,Additional Charges#21,Trip Total#22,Shared Trip Authorized#23,Trips Pooled#24,Pickup Centroid Latitude#25,Pickup Centroid Longitude#26,Pickup Centroid Location#27,Dropoff Centroid Latitude#28,Dropoff Centroid Longitude#29,Dropoff Centroid Location#30] csv\\n\""
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Trip Seconds', 'Trip Miles', 'Pickup Community Area', \n",
    "                                               'Dropoff Community Area', 'Shared Trip Authorized', 'Trips Pooled', \n",
    "                                                ], outputCol = 'features')\n",
    "v_df = vectorAssembler.transform(df)\n",
    "v_df = df.select(['features', 'Fare'])\n",
    "v_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into train / test\n",
    "\n",
    "splits = v_df.randomSplit([0.7, 0.3])\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/abertin/data/\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder.appName(\"TrafficCrashes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put /home/abertin/data/Traffic_Crashes.csv /user/abertin/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1-Instacart-AssociationMining.ipynb\tinstacart\r\n",
      "BigData_Assignment3_AlisonBertin.ipynb\tmobydick.txt\r\n",
      "BigData_Project.ipynb\t\t\tTraffic_Crashes.csv\r\n",
      "Crimes2001_to_present.csv\t\twordcount.sh\r\n",
      "food-inspections.csv\r\n"
     ]
    }
   ],
   "source": [
    "df = sc.textFile(\"/user/abertin/data/Traffic_Crashes.csv\").map(lambda line: line.split(\",\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 4G 16e",
   "language": "python",
   "name": "pyspark2_4g16e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
