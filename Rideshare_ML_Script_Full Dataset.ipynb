{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script was run with the full dataset only after the script with 1% of the data was run and confirmed as working and complete. Scripts were separated as a precautionary measure, especially considering potential running time. In general results were no better than the 1% dataset - and in some models, they were marginally worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, udf, month, year, date_format, datediff, from_unixtime, unix_timestamp\n",
    "from pyspark.sql.functions import date_trunc\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (StructType, StructField, DateType, BooleanType,\n",
    "                               DoubleType, IntegerType, StringType, TimestampType)\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 4 items\n",
      "-rw-r--r--   3 alphan alphan 1824926642 2019-05-25 04:44 /user/alphan/data/chicago_crimes.csv\n",
      "drwxr-xr-x   - alphan alphan          0 2019-06-04 02:09 /user/alphan/data/df.csv\n",
      "drwxr-xr-x   - alphan alphan          0 2019-06-04 02:12 /user/alphan/data/final_project_df.csv\n",
      "-rw-r--r--   3 alphan alphan  208276005 2019-04-30 20:10 /user/alphan/data/food-inspections.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/alphan/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('RideShare').getOrCreate()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '15g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','20g')])\n",
    "df = spark.read.csv(\"/user/alphan/data/final_project_df.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- pickupLat: double (nullable = true)\n",
      " |-- pickupLong: double (nullable = true)\n",
      " |-- dropoffLat: double (nullable = true)\n",
      " |-- dropoffLong: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('RideShare').getOrCreate()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '256g'),\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'),\n",
    "                                        ('spark.executor.cores', '16'),\n",
    "                                        ('spark.cores.max', '16'),\n",
    "                                        ('spark.driver.memory','256g'),\n",
    "                                        ('spark.sql.AutoBroadcastJoinThreshold', -1),\n",
    "                                        ('mapreduce.reduce.memory.mb',-1),\n",
    "                                        ('spark.yarn.executor.memoryOverhead', -1),\n",
    "                                        ('spark.kryoserializer.buffer.max.mb', '5g')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE to HDFS\n",
    "#fulldf = rides.join(spark_weather, rides.startTime == spark_weather.time, how='inner')\n",
    "#res_path = '/user/alphan/data/final_project_df.csv'\n",
    "#df.write.csv(path=res_path, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- pickupLat: double (nullable = true)\n",
      " |-- pickupLong: double (nullable = true)\n",
      " |-- dropoffLat: double (nullable = true)\n",
      " |-- dropoffLong: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[430.0,3.0,0.0,3....|\n",
      "|[368.0,1.9,1.0,44...|\n",
      "|[1142.0,14.7,1.0,...|\n",
      "|[1288.0,3.9,1.0,4...|\n",
      "|[205.0,1.2,0.0,10...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Assemble vectors and Scale:\n",
    "#After iterations examining individual impact, final variable 'columns' below does not contain Longitude & Latitude for easier running\n",
    "\n",
    "columns = ['seconds','miles','shared','communityPickup','communityDropoff','humidity', \n",
    "'apparentTemperature','precipIntensity',\n",
    "'precipProbability', 'temperature', 'Cloudy','Rainy', 'Snowy','month','day', 'hour']\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler,StandardScaler\n",
    "vectorAssembler = VectorAssembler(inputCols = columns, outputCol = 'features')# 'fare', 'addCharge', 'tripTotal'\n",
    "ml_data=vectorAssembler.transform(df)\n",
    "ml_data.select(\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[430.0,3.0,0.0,3....|[0.65134636695971...|\n",
      "|[368.0,1.9,1.0,44...|[0.55743130939807...|\n",
      "|[1142.0,14.7,1.0,...|[1.72985476992555...|\n",
      "|[1288.0,3.9,1.0,4...|[1.95100958289327...|\n",
      "|[205.0,1.2,0.0,10...|[0.31052559355055...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standardscaler=StandardScaler().setInputCol('features').setOutputCol('scaled_features')\n",
    "scaled_data=standardscaler.fit(ml_data).transform(ml_data)\n",
    "scaled_data.select('features','scaled_features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|     scaled_features|fare|\n",
      "+--------------------+----+\n",
      "|[0.65134636695971...| 7.5|\n",
      "|[0.55743130939807...| 5.0|\n",
      "|[1.72985476992555...|17.5|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vfull_df = scaled_data.select(['scaled_features', 'fare'])\n",
    "vfull_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of some of the models below changed noticeably for the better after setting the seed, and thus may differ slightly from the results from the presentation slide. The previous script did not have a seed setting. The rest of the script remains as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "#splits = scaled_data.randomSplit([0.99, 0.01], seed=SEED)\n",
    "#small_df = splits[1]\n",
    "\n",
    "#Data is not split, all of it is used\n",
    "small_split = scaled_data.randomSplit([0.7, 0.3],seed=SEED)\n",
    "train_df = small_split[0]\n",
    "test_df = small_split[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'fare')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "dt_rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "dt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "dt_r2 = dt_evaluator2.evaluate(dt_predictions)\n",
    "dt_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "dt_mae= dt_evaluator3.evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.18569\n",
      "R-Squared (R2) on test data = 0.783109\n",
      "Mean Absolute Error (MAE) on test data = 1.6739\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % dt_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % dt_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % dt_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from FeatureImportanceSelector import ExtractFeatureImp, FeatureImpSelector\n",
    "ExtractFeatureImp(mod.stages[-1].featureImportances, dt_predictions, \"features_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788758</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110000</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098925</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001299</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000845</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values             features\n",
       "1   0.788758                miles\n",
       "2   0.110000               shared\n",
       "0   0.098925              seconds\n",
       "4   0.001299     communityDropoff\n",
       "3   0.000845      communityPickup\n",
       "15  0.000173                 hour\n",
       "5   0.000000             humidity\n",
       "6   0.000000  apparentTemperature\n",
       "7   0.000000      precipIntensity\n",
       "8   0.000000    precipProbability\n",
       "9   0.000000          temperature\n",
       "10  0.000000               Cloudy\n",
       "11  0.000000                Rainy\n",
       "12  0.000000                Snowy\n",
       "13  0.000000                month\n",
       "14  0.000000                  day"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(dt_model.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|fare|            features|\n",
      "+------------------+----+--------------------+\n",
      "| 4.418849079762522| 5.0|[3.0,1.8,1.0,2.0,...|\n",
      "| 4.410442506890022| 5.0|[3.0,2.1,0.0,25.0...|\n",
      "| 4.429378898540901| 5.0|[3.0,2.4,1.0,69.0...|\n",
      "| 4.517293369824973| 7.5|[3.0,2.9,1.0,7.0,...|\n",
      "|3.1454906855994476| 7.5|[4.0,0.1,1.0,32.0...|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'fare', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'fare', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "gbt_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "gbt_r2 = gbt_evaluator2.evaluate(gbt_predictions)\n",
    "gbt_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "gbt_mae = gbt_evaluator3.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.05265\n",
      "R-Squared (R2) on test data = 0.800673\n",
      "Mean Absolute Error (MAE) on test data = 1.58199\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % gbt_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % gbt_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % gbt_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348159</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330531</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110286</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081520</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.043315</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035082</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.019788</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016873</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008103</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004432</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000676</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000646</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000588</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      values             features\n",
       "1   0.348159                miles\n",
       "0   0.330531              seconds\n",
       "2   0.110286               shared\n",
       "3   0.081520      communityPickup\n",
       "15  0.043315                 hour\n",
       "4   0.035082     communityDropoff\n",
       "14  0.019788                  day\n",
       "5   0.016873             humidity\n",
       "9   0.008103          temperature\n",
       "8   0.004432    precipProbability\n",
       "7   0.000676      precipIntensity\n",
       "6   0.000646  apparentTemperature\n",
       "13  0.000588                month\n",
       "10  0.000000               Cloudy\n",
       "11  0.000000                Rainy\n",
       "12  0.000000                Snowy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(gbt_model.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+--------------------+\n",
      "|       prediction|fare|            features|\n",
      "+-----------------+----+--------------------+\n",
      "|4.914244067686214| 5.0|[3.0,1.8,1.0,2.0,...|\n",
      "| 5.28916467276556| 5.0|[3.0,2.1,0.0,25.0...|\n",
      "|4.851192640180555| 5.0|[3.0,2.4,1.0,69.0...|\n",
      "|4.952220950046641| 7.5|[3.0,2.9,1.0,7.0,...|\n",
      "|4.534225149458597| 7.5|[4.0,0.1,1.0,32.0...|\n",
      "+-----------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'fare')\n",
    "rfModel = rf.fit(train_df)\n",
    "rf_predictions = rfModel.transform(test_df)\n",
    "rf_predictions.select('prediction', 'fare', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rf_rmse = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "rf_evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rf_r2 = rf_evaluator2.evaluate(rf_predictions)\n",
    "rf_evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "rf_mae = rf_evaluator3.evaluate(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.27499\n",
      "R-Squared (R2) on test data = 0.770778\n",
      "Mean Absolute Error (MAE) on test data = 1.75036\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rf_rmse)\n",
    "print(\"R-Squared (R2) on test data = %g\" % rf_r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % rf_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.371706e-01</td>\n",
       "      <td>miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.725979e-01</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.543686e-02</td>\n",
       "      <td>shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.461566e-02</td>\n",
       "      <td>communityDropoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.849393e-02</td>\n",
       "      <td>communityPickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.312816e-03</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.041749e-04</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.189574e-04</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.667602e-05</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.697081e-05</td>\n",
       "      <td>apparentTemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.275012e-06</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.986494e-07</td>\n",
       "      <td>precipIntensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>precipProbability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          values             features\n",
       "1   4.371706e-01                miles\n",
       "0   3.725979e-01              seconds\n",
       "2   8.543686e-02               shared\n",
       "4   7.461566e-02     communityDropoff\n",
       "3   2.849393e-02      communityPickup\n",
       "15  1.312816e-03                 hour\n",
       "14  2.041749e-04                  day\n",
       "13  1.189574e-04                month\n",
       "5   2.667602e-05             humidity\n",
       "6   1.697081e-05  apparentTemperature\n",
       "9   5.275012e-06          temperature\n",
       "7   1.986494e-07      precipIntensity\n",
       "8   0.000000e+00    precipProbability\n",
       "10  0.000000e+00               Cloudy\n",
       "11  0.000000e+00                Rainy\n",
       "12  0.000000e+00                Snowy"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame(rfModel.featureImportances.toArray(), columns=[\"values\"])\n",
    "features_col = pd.Series(columns)\n",
    "model[\"features\"] = features_col\n",
    "model.sort_values(\"values\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.002341637431339443,0.9493864709339118,-3.430047867004976,0.0,4.679378168085919e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Intercept: 3.6258245818048502\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='fare', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.318745\n",
      "r2: 0.764394\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n",
    "print(\"MAE: %f\" % trainingSummary.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- precipIntensity: double (nullable = true)\n",
      " |-- precipProbability: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- Cloudy: double (nullable = true)\n",
      " |-- Rainy: double (nullable = true)\n",
      " |-- Snowy: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_data = test_df.select(col(\"fare\").alias(\"label\"), *columns)  \n",
    "lr_data.printSchema()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "rfr = RandomForestRegressor(labelCol=\"label\", featuresCol=\"scaled_features\")\n",
    "stages = [vectorAssembler, standardscaler, rfr]\n",
    "pipe = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorParam = ParamGridBuilder() \\\n",
    ".addGrid(rfr.maxDepth, [4, 6,8]) \\\n",
    ".addGrid(rfr.maxBins, [5, 10, 15]) \\\n",
    ".addGrid(rfr.impurity, [\"variance\"]) \\\n",
    ".build()\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipe,\n",
    "                         estimatorParamMaps=estimatorParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "cvmodel = crossval.fit(lr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=RegressionEvaluator()\n",
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\")\n",
    "eval_r2 = RegressionEvaluator(metricName=\"r2\")\n",
    "eval_mae = RegressionEvaluator(metricName=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1604885811601906\n",
      "0.786526112532769\n",
      "1.5975821815077242\n"
     ]
    }
   ],
   "source": [
    "#Not sure it matters what data we use here\n",
    "print(eval_rmse.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_r2.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_mae.evaluate(cvmodel.transform(lr_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(labelCol=\"label\", featuresCol=\"scaled_features\")\n",
    "stages = [vectorAssembler, standardscaler, gbt]\n",
    "pipe = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorParam = ParamGridBuilder() \\\n",
    ".addGrid(rfr.maxDepth, [4, 6,8]) \\\n",
    ".addGrid(rfr.maxBins, [5, 10, 15]) \\\n",
    ".addGrid(rfr.impurity, [\"variance\"]) \\\n",
    ".build()\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipe,\n",
    "                         estimatorParamMaps=estimatorParam,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "\n",
    "cvmodel = crossval.fit(lr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=RegressionEvaluator()\n",
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\")\n",
    "eval_r2 = RegressionEvaluator(metricName=\"r2\")\n",
    "eval_mae = RegressionEvaluator(metricName=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0066228031720823\n",
      "0.806805747672977\n",
      "1.5554689718064223\n"
     ]
    }
   ],
   "source": [
    "print(eval_rmse.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_r2.evaluate(cvmodel.transform(lr_data)))\n",
    "print(eval_mae.evaluate(cvmodel.transform(lr_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
