{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (StructType, StructField, DateType, BooleanType,\n",
    "                               DoubleType, IntegerType, StringType, TimestampType)\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hdfs dfs -put /home/mechols/data/rows.csv /user/mechols/data/\n",
    "#!hdfs dfs -put /home/mechols/data/AllWeather.csv /user/mechols/data/\n",
    "#!hdfs dfs -put /home/mechols/data/weather_data.csv /user/mechols/data/\n",
    "#!hdfs dfs -rm -r /user/mechols/data/fulldf.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 8 items\n",
      "-rw-r--r--   3 mechols mechols      375182 2019-05-26 23:15 /user/mechols/data/AllWeather.csv\n",
      "-rw-r--r--   3 mechols mechols        1708 2019-05-17 14:10 /user/mechols/data/chicago_community_names.csv\n",
      "-rw-r--r--   3 mechols mechols  1804333782 2019-05-16 21:03 /user/mechols/data/chicago_crimes.csv\n",
      "-rw-r--r--   3 mechols mechols   208276005 2019-04-30 20:04 /user/mechols/data/food-inspections.csv\n",
      "drwxr-xr-x   - mechols mechols           0 2019-06-03 15:23 /user/mechols/data/fulldf.csv\n",
      "-rw-r--r--   3 mechols mechols 11980344386 2019-05-21 14:25 /user/mechols/data/rows.csv\n",
      "drwxr-xr-x   - mechols mechols           0 2019-05-26 17:22 /user/mechols/data/weatherTrial\n",
      "drwxr-xr-x   - mechols mechols           0 2019-05-25 11:15 /user/mechols/data/weather_data\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/mechols/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding access for Alison and Alpha\n",
    "#!hdfs dfs -chmod -R a+rX /user/mechols/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing access\n",
    "#!hdfs dfs -chmodd -R go-rwx /user/$USER/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('RideShare').getOrCreate()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '256g'),\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'),\n",
    "                                        ('spark.executor.cores', '16'),\n",
    "                                        ('spark.cores.max', '16'),\n",
    "                                        ('spark.driver.memory','256g'),\n",
    "                                        ('spark.sql.AutoBroadcastJoinThreshold', -1),\n",
    "                                        ('mapreduce.reduce.memory.mb',-1),\n",
    "                                        ('spark.yarn.executor.memoryOverhead', -1),\n",
    "                                        ('spark.kryoserializer.buffer.max.mb', '5g')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Spark Dataframes of Weather Data and RideShare Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Spark Dataframe of all months (smoother than union)\n",
    "weatherT = sqlContext.read.format('csv').options(header='true', inferSchema = True).load(\"/user/mechols/data/AllWeather.csv\")\n",
    "initial = weatherT.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = sqlContext.read.format('csv').options(header='true', inferSchema = True).load(\"/user/mechols/data/rows.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RideShare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Rideshare df by matching the order of dates to the weather data and converting them to timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = rides.withColumn('Trip Start Timestamp', from_unixtime(unix_timestamp(col(('Trip Start Timestamp')), \"MM/dd/yyy hh:mm:ss aa\"), \"yyyy-MM-dd HH\"))\n",
    "rides = rides.withColumn('Trip End Timestamp', from_unixtime(unix_timestamp(col(('Trip End Timestamp')), \"MM/dd/yyy hh:mm:ss aa\"), \"yyyy-MM-dd HH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = rides.withColumn(\"Trip Start Timestamp\", rides[\"Trip Start Timestamp\"].cast(TimestampType()))\n",
    "rides = rides.withColumn(\"Trip End Timestamp\", rides[\"Trip End Timestamp\"].cast(TimestampType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: timestamp (nullable = true)\n",
      " |-- Trip End Timestamp: timestamp (nullable = true)\n",
      " |-- Trip Seconds: integer (nullable = true)\n",
      " |-- Trip Miles: double (nullable = true)\n",
      " |-- Pickup Census Tract: long (nullable = true)\n",
      " |-- Dropoff Census Tract: long (nullable = true)\n",
      " |-- Pickup Community Area: integer (nullable = true)\n",
      " |-- Dropoff Community Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: integer (nullable = true)\n",
      " |-- Additional Charges: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- Shared Trip Authorized: boolean (nullable = true)\n",
      " |-- Trips Pooled: integer (nullable = true)\n",
      " |-- Pickup Centroid Latitude: double (nullable = true)\n",
      " |-- Pickup Centroid Longitude: double (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rides.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows where missing values are in features that cannot be imputed accurately.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39202018"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides = rides.where(col(\"Trip Miles\").isNotNull())\n",
    "rides = rides.where(col(\"Pickup Community Area\").isNotNull())\n",
    "rides = rides.where(col(\"Dropoff Community Area\").isNotNull())\n",
    "rides = rides.where(col(\"Trip Seconds\") != 0)\n",
    "rides = rides.where(col(\"Trip Miles\") != 0)\n",
    "rides = rides.where(col(\"Fare\").isNotNull())\n",
    "rides = rides.where(col(\"Fare\") != 0)\n",
    "rides.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns of features that will not be available for test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Pickup Census Tract', \"Dropoff Census Tract\", \"Tip\", \"Trips Pooled\",\"tripID\",\n",
    "             'startTime',\"endTime\",\"addCharge\",\"tripTotal\",\"pickupLoc\",\"dropoffLoc\"]\n",
    "rides = rides.select([column for column in rides.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weatherT.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns of features that will not be available for test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.drop([\"_c0\",\"Unnamed: 0\",\"cloudCover\",\"dewPoint\",\"icon\",\"pressure\",\"uvIndex\",\"visibility\",\"windBearing\",\"windGust\",\"windSpeed\", \"precipType\", \"precipAccumulation\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting datatype of time fromt a string to a timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "weather['time'] = pd.to_datetime(weather['time'], format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping weather types by Cloudy, Rainy, Snowy, or Clear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type = {\"Foggy\":\"Cloudy\",\"Mostly Cloudy\":\"Cloudy\",\"Overcast\":\"Cloudy\",\"Windy and Partly Cloudy\":\"Cloudy\",\n",
    "        \"Windy and Mostly Cloudy\":\"Cloudy\",\"Partly Cloudy\":\"Cloudy\",\n",
    "        \"Rain\":\"Rain\", \"Drizzle\":\"Rain\",\"Light Rain\":\"Rain\",\n",
    "        \"Heavy Snow\": \"Snow\",\"Possible Light Snow\": \"Snow\",\"Light Snow\": \"Snow\",\"Snow\": \"Snow\",\n",
    "        \"Clear\":\"Clear\"}\n",
    "\n",
    "weather['summary'] = weather['summary'].map(Type)\n",
    "weather['Cloudy'] = np.where(weather['summary']==\"Cloudy\", 1, 0)\n",
    "weather['Rainy'] = np.where(weather['summary']==\"Rain\", 1, 0)\n",
    "weather['Snowy'] = np.where(weather['summary']==\"Snow\", 1, 0)\n",
    "weather = weather.drop(\"summary\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Rainy</th>\n",
       "      <th>Snowy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2018-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.11</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.11</td>\n",
       "      <td>2018-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.95</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2018-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.08</td>\n",
       "      <td>2018-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.43</td>\n",
       "      <td>2018-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apparentTemperature  humidity  precipIntensity  precipProbability  \\\n",
       "0                49.99      0.72              0.0                0.0   \n",
       "1                50.11      0.71              0.0                0.0   \n",
       "2                48.95      0.67              0.0                0.0   \n",
       "3                51.08      0.64              0.0                0.0   \n",
       "4                50.43      0.61              0.0                0.0   \n",
       "\n",
       "   temperature                time  Cloudy  Rainy  Snowy  \n",
       "0        49.99 2018-11-01 00:00:00       1      0      0  \n",
       "1        50.11 2018-11-01 01:00:00       1      0      0  \n",
       "2        49.99 2018-11-01 02:00:00       1      0      0  \n",
       "3        51.08 2018-11-01 03:00:00       1      0      0  \n",
       "4        50.43 2018-11-01 04:00:00       1      0      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing missing rows in weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Rainy</th>\n",
       "      <th>Snowy</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>42.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.76</td>\n",
       "      <td>2018-11-04 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>21.80</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.65</td>\n",
       "      <td>2018-11-11 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>33.36</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.36</td>\n",
       "      <td>2018-11-12 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>40.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.05</td>\n",
       "      <td>2018-12-20 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>33.07</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.64</td>\n",
       "      <td>33.07</td>\n",
       "      <td>2019-02-06 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>-8.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.67</td>\n",
       "      <td>2019-02-08 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>24.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.40</td>\n",
       "      <td>32.49</td>\n",
       "      <td>2019-02-20 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>31.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.55</td>\n",
       "      <td>2019-02-22 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>13.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.53</td>\n",
       "      <td>2019-02-24 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>8.27</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.55</td>\n",
       "      <td>2019-02-26 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>26.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.79</td>\n",
       "      <td>2019-03-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>8.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.51</td>\n",
       "      <td>2019-03-03 11:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>7.86</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.20</td>\n",
       "      <td>2019-03-03 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>-12.22</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2019-03-04 11:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.02</td>\n",
       "      <td>2019-03-06 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>16.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.33</td>\n",
       "      <td>2019-03-07 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>26.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.34</td>\n",
       "      <td>2019-03-07 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>29.56</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.94</td>\n",
       "      <td>38.40</td>\n",
       "      <td>2019-03-09 18:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>28.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.36</td>\n",
       "      <td>2019-03-10 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>57.25</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.25</td>\n",
       "      <td>2019-03-13 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>30.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.43</td>\n",
       "      <td>2019-03-15 18:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>22.14</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.30</td>\n",
       "      <td>2019-03-16 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>34.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.60</td>\n",
       "      <td>2019-03-16 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>33.44</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.68</td>\n",
       "      <td>2019-03-21 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>43.96</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.96</td>\n",
       "      <td>2019-03-24 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>46.34</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.34</td>\n",
       "      <td>2019-03-24 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>24.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.08</td>\n",
       "      <td>2019-03-25 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      apparentTemperature  humidity  precipIntensity  precipProbability  \\\n",
       "78                  42.64      0.75           0.0000               0.00   \n",
       "239                 21.80      0.71           0.0000               0.00   \n",
       "262                 33.36      0.76           0.0000               0.00   \n",
       "1173                40.32      0.76           0.0000               0.00   \n",
       "2324                33.07      0.94           0.0092               0.64   \n",
       "2371                -8.05      0.75           0.0000               0.00   \n",
       "2670                24.98      0.98           0.0052               0.40   \n",
       "2717                31.76      0.67           0.0000               0.00   \n",
       "2764                13.55      0.72           0.0000               0.00   \n",
       "2805                 8.27      0.75           0.0000               0.00   \n",
       "2885                26.40      0.69           0.0000               0.00   \n",
       "2927                 8.48      0.66           0.0000               0.00   \n",
       "2928                 7.86      0.63           0.0000               0.00   \n",
       "2949               -12.22      0.57           0.0000               0.00   \n",
       "2985                 0.15      0.60           0.0000               0.00   \n",
       "3008                16.64      0.60           0.0000               0.00   \n",
       "3020                26.34      0.58           0.0000               0.00   \n",
       "3072                29.56      0.96           0.0553               0.94   \n",
       "3081                28.10      0.80           0.0000               0.00   \n",
       "3165                57.25      0.71           0.0000               0.00   \n",
       "3213                30.91      0.66           0.0000               0.00   \n",
       "3224                22.14      0.74           0.0000               0.00   \n",
       "3234                34.61      0.49           0.0000               0.00   \n",
       "3338                33.44      0.87           0.0000               0.00   \n",
       "3413                43.96      0.53           0.0000               0.00   \n",
       "3416                46.34      0.69           0.0000               0.00   \n",
       "3435                24.84      0.81           0.0000               0.00   \n",
       "\n",
       "      temperature                time  Cloudy  Rainy  Snowy  Diff  \n",
       "78          47.76 2018-11-04 07:00:00       1      0      0   2.0  \n",
       "239         28.65 2018-11-11 01:00:00       1      0      0   2.0  \n",
       "262         33.36 2018-11-12 01:00:00       1      0      0   2.0  \n",
       "1173        44.05 2018-12-20 01:00:00       1      0      0   2.0  \n",
       "2324        33.07 2019-02-06 01:00:00       1      0      0   2.0  \n",
       "2371        10.67 2019-02-08 01:00:00       1      0      0   2.0  \n",
       "2670        32.49 2019-02-20 13:00:00       1      0      0   2.0  \n",
       "2717        35.55 2019-02-22 13:00:00       1      0      0   2.0  \n",
       "2764        26.53 2019-02-24 13:00:00       1      0      0   2.0  \n",
       "2805        18.55 2019-02-26 07:00:00       1      0      0   2.0  \n",
       "2885        31.79 2019-03-01 16:00:00       1      0      0   2.0  \n",
       "2927        19.51 2019-03-03 11:00:00       1      0      0   2.0  \n",
       "2928        19.20 2019-03-03 13:00:00       1      0      0   2.0  \n",
       "2949         3.19 2019-03-04 11:00:00       0      0      0   2.0  \n",
       "2985        13.02 2019-03-06 00:00:00       0      0      0   2.0  \n",
       "3008        25.33 2019-03-07 00:00:00       0      0      0   2.0  \n",
       "3020        26.34 2019-03-07 13:00:00       1      0      0   2.0  \n",
       "3072        38.40 2019-03-09 18:00:00       0      1      0   2.0  \n",
       "3081        37.36 2019-03-10 04:00:00       1      0      0   2.0  \n",
       "3165        57.25 2019-03-13 17:00:00       1      0      0   2.0  \n",
       "3213        38.43 2019-03-15 18:00:00       1      0      0   2.0  \n",
       "3224        29.30 2019-03-16 06:00:00       0      0      0   2.0  \n",
       "3234        38.60 2019-03-16 17:00:00       1      0      0   2.0  \n",
       "3338        38.68 2019-03-21 02:00:00       1      0      0   2.0  \n",
       "3413        43.96 2019-03-24 06:00:00       1      0      0   2.0  \n",
       "3416        46.34 2019-03-24 10:00:00       0      0      0   2.0  \n",
       "3435        34.08 2019-03-25 06:00:00       1      0      0   2.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 3596\n",
    "weather = weather.sort_values(\"time\")\n",
    "datediff = []\n",
    "datediff.append(pd.Timedelta(weather.time.iloc[0] - weather.time.iloc[0]).seconds/3600)\n",
    "for i in range(1,len(weather)):\n",
    "    j = i - 1\n",
    "    datediff.append(pd.Timedelta(weather.time.iloc[i] - weather.time.iloc[j]).seconds/3600)\n",
    "weather[\"Diff\"] = datediff\n",
    "listplus = weather.loc[weather.Diff > 1]\n",
    "linestoadd = len(listplus)\n",
    "listplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors Left: 27\n",
      "Errors Left: 26\n",
      "Errors Left: 25\n",
      "Errors Left: 24\n",
      "Errors Left: 23\n",
      "Errors Left: 22\n",
      "Errors Left: 21\n",
      "Errors Left: 20\n",
      "Errors Left: 19\n",
      "Errors Left: 18\n",
      "Errors Left: 17\n",
      "Errors Left: 16\n",
      "Errors Left: 15\n",
      "Errors Left: 14\n",
      "Errors Left: 13\n",
      "Errors Left: 12\n",
      "Errors Left: 11\n",
      "Errors Left: 10\n",
      "Errors Left: 9\n",
      "Errors Left: 8\n",
      "Errors Left: 7\n",
      "Errors Left: 6\n",
      "Errors Left: 5\n",
      "Errors Left: 4\n",
      "Errors Left: 3\n",
      "Errors Left: 2\n",
      "Errors Left: 1\n",
      "Errors Left: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(listplus)):   \n",
    "    weather = weather.sort_values(\"time\")\n",
    "    datediff = []\n",
    "    datediff.append(pd.Timedelta(weather.time.loc[0] - weather.time.loc[0]).seconds/3600)\n",
    "    for i in range(1,len(weather)):\n",
    "        j = i - 1\n",
    "        datediff.append(pd.Timedelta(weather.time.iloc[i] - weather.time.iloc[j]).seconds/3600)\n",
    "    weather[\"Diff\"] = datediff\n",
    "    listplus = weather.index[weather.Diff > 1]\n",
    "    j = listplus[0]\n",
    "    i = j - 1\n",
    "    weather.loc[z] = [(weather.loc[i][0]+weather.loc[j][0])/2, (weather.loc[i][1]+weather.loc[j][1])/2,\n",
    "                              (weather.loc[i][2]+weather.loc[j][2])/2, (weather.loc[i][3]+weather.loc[j][3])/2,\n",
    "                              (weather.loc[i][4]+weather.loc[j][4])/2, (weather.loc[i][5] + pd.Timedelta(hours=1)),\n",
    "                              (weather.loc[i][6]+weather.loc[j][6])/2,(weather.loc[i][7]+weather.loc[j][7])/2,\n",
    "                              (weather.loc[i][8]+weather.loc[j][8])/2,1]\n",
    "    z += 1\n",
    "    print(\"Errors Left:\",len(listplus))\n",
    "print(\"Errors Left:\",len(listplus)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculates if any duplicates were created using the function above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64Index([], dtype='int64'), array([], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = weather.time\n",
    "weather.index[times.isin(times[times.duplicated()])].sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.drop(\"Diff\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting timestamp of weather data to match rides data for joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.time = weather.time.dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_weather = sqlContext.createDataFrame(weather)\n",
    "spark_weather = spark_weather.withColumn(\"time\", spark_weather[\"time\"].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apparentTemperature', 'double'),\n",
       " ('humidity', 'double'),\n",
       " ('precipIntensity', 'double'),\n",
       " ('precipProbability', 'double'),\n",
       " ('temperature', 'double'),\n",
       " ('time', 'timestamp'),\n",
       " ('Cloudy', 'double'),\n",
       " ('Rainy', 'double'),\n",
       " ('Snowy', 'double')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trip ID', 'string'),\n",
       " ('Trip Start Timestamp', 'timestamp'),\n",
       " ('Trip End Timestamp', 'timestamp'),\n",
       " ('Trip Seconds', 'int'),\n",
       " ('Trip Miles', 'double'),\n",
       " ('Pickup Community Area', 'int'),\n",
       " ('Dropoff Community Area', 'int'),\n",
       " ('Fare', 'double'),\n",
       " ('Additional Charges', 'double'),\n",
       " ('Trip Total', 'double'),\n",
       " ('Shared Trip Authorized', 'boolean'),\n",
       " ('Pickup Centroid Latitude', 'double'),\n",
       " ('Pickup Centroid Longitude', 'double'),\n",
       " ('Pickup Centroid Location', 'string'),\n",
       " ('Dropoff Centroid Latitude', 'double'),\n",
       " ('Dropoff Centroid Longitude', 'double'),\n",
       " ('Dropoff Centroid Location', 'string')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning feature names to make indexing easier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tripID: string (nullable = true)\n",
      " |-- startTime: timestamp (nullable = true)\n",
      " |-- endTime: timestamp (nullable = true)\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- miles: double (nullable = true)\n",
      " |-- communityPickup: integer (nullable = true)\n",
      " |-- communityDropoff: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- addCharge: double (nullable = true)\n",
      " |-- tripTotal: double (nullable = true)\n",
      " |-- shared: boolean (nullable = true)\n",
      " |-- pickupLat: double (nullable = true)\n",
      " |-- pickupLong: double (nullable = true)\n",
      " |-- pickupLoc: string (nullable = true)\n",
      " |-- dropoffLat: double (nullable = true)\n",
      " |-- dropoffLong: double (nullable = true)\n",
      " |-- dropoffLoc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oldColumns = rides.schema.names\n",
    "newColumns = [\"tripID\",\"startTime\",\"endTime\",\"seconds\",\"miles\",\"communityPickup\",\"communityDropoff\",\"fare\",\"addCharge\",\n",
    "              \"tripTotal\",\"shared\",\"pickupLat\",\"pickupLong\",\"pickupLoc\",\"dropoffLat\",\"dropoffLong\",\"dropoffLoc\"]\n",
    "rides = reduce(lambda rides, idx: rides.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), rides)\n",
    "rides.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Joining rides and weather data on time of occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = rides.join(spark_weather, rides.startTime == spark_weather.time, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirming shape of new dataframe is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(fulldf.count())\n",
    "#print(len(fulldf.dtypes))\n",
    "#print(fulldf.count() * (len(fulldf.dtypes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns that are redundent or won't be applicable for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\"tripID\",'startTime',\"endTime\",\"addCharge\",\"tripTotal\",\"pickupLoc\",\"dropoffLoc\"]\n",
    "fulldf = fulldf.select([column for column in fulldf.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for null/NaN elements within columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------------+----------------+----+------+---------+----------+----------+-----------+-------------------+--------+---------------+-----------------+-----------+----+------+-----+-----+\n",
      "|seconds|miles|communityPickup|communityDropoff|fare|shared|pickupLat|pickupLong|dropoffLat|dropoffLong|apparentTemperature|humidity|precipIntensity|precipProbability|temperature|time|Cloudy|Rainy|Snowy|\n",
      "+-------+-----+---------------+----------------+----+------+---------+----------+----------+-----------+-------------------+--------+---------------+-----------------+-----------+----+------+-----+-----+\n",
      "|      0|    0|              0|               0|   0|     0|        0|         0|         0|          0|                  0|       0|              0|                0|          0|   0|     0|    0|    0|\n",
      "+-------+-----+---------------+----------------+----+------+---------+----------+----------+-----------+-------------------+--------+---------------+-----------------+-----------+----+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_not_null(c, nan_as_null=False):\n",
    "    pred = col(c).isNull() & (isnan(c) if nan_as_null else lit(True))\n",
    "    return sum(pred.cast(\"integer\")).alias(c)\n",
    "\n",
    "fulldf.agg(*[count_not_null(c) for c in fulldf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing cached images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[seconds: int, miles: double, communityPickup: int, communityDropoff: int, fare: double, shared: boolean, pickupLat: double, pickupLong: double, dropoffLat: double, dropoffLong: double, apparentTemperature: double, humidity: double, precipIntensity: double, precipProbability: double, temperature: double, time: timestamp, Cloudy: double, Rainy: double, Snowy: double]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.unpersist()\n",
    "spark_weather.unpersist()\n",
    "fulldf.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding columns for Month/Day/Year and dropping the time column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = fulldf.withColumn('month', month(fulldf['time']))\\\n",
    ".withColumn('day', dayofweek(fulldf['time']))\\\n",
    ".withColumn('hour', hour(fulldf['time']))\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\"time\"]\n",
    "fulldf = fulldf.select([column for column in fulldf.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing dataframe back to HDFS for use by the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE to HDFS\n",
    "\n",
    "res_path = '/user/mechols/data/fulldf.csv'\n",
    "fulldf.write.csv(path=res_path, header=True, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 4G 32e",
   "language": "python",
   "name": "pyspark2_4g32e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
